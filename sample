set define off;

CREATE OR REPLACE PACKAGE "IBMBUSER.IBMB_ARCHIVE_PKG" 
AS
PROCEDURE ARCHVICE_EVENT;
PROCEDURE ARCHVICE_NOTIFICATION;
PROCEDURE ARCHVICE_PUSH_NOTI_AUDIT;
PROCEDURE ARCHVICE_SEGMENT_UPLOAD_FILE;
PROCEDURE ARCHVICE_PAGE_VIEW_REPORT;
PROCEDURE ARCHVICE_CA_REQUEST_AUDIT;
PROCEDURE ARCHIVE_CS_TRANSACTION_AUDIT;
END; 

/
create or replace PACKAGE BODY "IBMB_ARCHIVE_PKG" 
IS
   PROCEDURE ARCHVICE_EVENT 
   IS
     CURSOR c_archiveData IS
		SELECT * FROM IBMBUSER.EVENT@ARCH_CIDB_IBMB WHERE CREATED_DATE <= add_months(sysdate, -3);
	TYPE t_data IS TABLE OF  c_archiveData%ROWTYPE;
	chunk_size CONSTANT INTEGER :=100000;
	l_data t_data;
	lc_out  VARCHAR2(512);
    reccount NUMBER;
    totalRecords NUMBER;
   BEGIN
	OPEN c_archiveData;
    totalRecords := 0;
    LOOP
      BEGIN
            FETCH c_archiveData BULK COLLECT INTO l_data LIMIT chunk_size;
            reccount := l_data.COUNT;
            totalRecords := totalRecords + reccount;
            FORALL i IN 1..reccount
                INSERT INTO IBMBARCHIVE.EVENT_ARCHIVE(EVENT_ID,EVENT_TYPE,CIN,CIF,STATUS,PARAM1,PARAM2,PARAM3,PARAM4,PARAM5,CREATED_BY,
				CREATED_DATE,MODIFIED_BY,MODIFIED_DATE,OCCURRENCE,FREQUENCY,DEVICE_ID) 
                VALUES
                (l_data(i).EVENT_ID,l_data(i).EVENT_TYPE,l_data(i).CIN,l_data(i).CIF,l_data(i).STATUS,l_data(i).PARAM1,l_data(i).PARAM2,l_data(i).PARAM3,l_data(i).PARAM4,l_data(i).PARAM5,
                l_data(i).CREATED_BY,l_data(i).CREATED_DATE,l_data(i).MODIFIED_BY,l_data(i).MODIFIED_DATE,l_data(i).OCCURRENCE,l_data(i).FREQUENCY,
                l_data(i).DEVICE_ID);
            lc_out := 'INS';
            FOR i IN 1..reccount
				LOOP
                  DELETE FROM IBMBUSER.EVENT@ARCH_CIDB_IBMB WHERE EVENT_ID = l_data(i).EVENT_ID;
				END LOOP;
            lc_out := lc_out || '-DEL-';
            IF SQL%FOUND THEN
                lc_out := lc_out || 'SUCCESS';
                INSERT INTO IBMB_ARCHIVE_AUDIT (TBL_NAME, RECOUNT, STATUS,ERR_TEXT) VALUES ('EVENT',reccount,'1',lc_out);
                COMMIT;
            END IF;
            EXIT WHEN c_archiveData%NOTFOUND;
        EXCEPTION
            WHEN OTHERS
            THEN
                ROLLBACK;
                lc_out := lc_out || 'Error:' || SQLERRM;
				totalRecords := totalRecords - reccount;
                INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('EVENT',reccount,'0',lc_out);
                COMMIT;
        END;
	END LOOP;
	CLOSE c_archiveData;
    INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('EVENT',totalRecords,'1','JOB_COMPLETED');
    COMMIT;
   END ARCHVICE_EVENT;

PROCEDURE ARCHVICE_NOTIFICATION
   IS
	CURSOR c_archiveData IS
		SELECT * FROM IBMBUSER.NOTIFICATION@ARCH_CIDB_IBMB WHERE CREATED_ON <= add_months(sysdate, -6);
	TYPE t_data IS TABLE OF  c_archiveData%ROWTYPE;
	chunk_size CONSTANT INTEGER :=100000;
	l_data t_data;
	lc_out  VARCHAR2(512);
    reccount NUMBER;
	totalRecords NUMBER;


BEGIN
	totalRecords := 0;
	OPEN c_archiveData;
		LOOP
			BEGIN
            FETCH c_archiveData BULK COLLECT INTO l_data LIMIT chunk_size;
            reccount := l_data.COUNT;
			totalRecords := totalRecords + reccount;
            FORALL i IN 1..reccount
                INSERT INTO IBMBARCHIVE.NOTIFICATION_ARCHIVE(NOTIFICATION_ID,CIF,TITTLE,MESSAGE,CATEGORY,ACTION,ACTION_LABEL,ACTION_URL,READ_STATUS,DELIVERY_METHOD,
				DELIVERY_STATUS,CREATED_BY,CREATED_ON,MODIFIED_BY,MODIFIED_ON,SOURCE_TYPE,PARENT_ID,ERROR_CODE,ERROR_DESC,EVENT_TYPE,EXPIRY_DATE,LOCALE,ANDROID_IMAGE,
				IOS_MEDIA,REFERENCE_ID,TEMPLATE_TYPE,SUPRESSION_TYPE,CONTENT_PATH) 
                VALUES
                (l_data(i).NOTIFICATION_ID,l_data(i).CIF,l_data(i).TITTLE,l_data(i).MESSAGE,l_data(i).CATEGORY,l_data(i).ACTION,l_data(i).ACTION_LABEL,l_data(i).ACTION_URL,l_data(i).READ_STATUS,
                l_data(i).DELIVERY_METHOD,l_data(i).DELIVERY_STATUS,l_data(i).CREATED_BY,l_data(i).CREATED_ON,l_data(i).MODIFIED_BY,l_data(i).MODIFIED_ON,l_data(i).SOURCE_TYPE,l_data(i).PARENT_ID,
                l_data(i).ERROR_CODE,l_data(i).ERROR_DESC,l_data(i).EVENT_TYPE,l_data(i).EXPIRY_DATE,l_data(i).LOCALE,l_data(i).ANDROID_IMAGE,l_data(i).IOS_MEDIA,l_data(i).REFERENCE_ID,l_data(i).TEMPLATE_TYPE,
                l_data(i).SUPRESSION_TYPE,l_data(i).CONTENT_PATH);
            lc_out := 'INS';
            FOR i IN 1..reccount
				LOOP
                  DELETE FROM IBMBUSER.NOTIFICATION@ARCH_CIDB_IBMB WHERE NOTIFICATION_ID = l_data(i).NOTIFICATION_ID;
				END LOOP;
            lc_out := lc_out || '-DEL-';
            IF SQL%FOUND THEN
                lc_out := lc_out || 'SUCCESS';
                INSERT INTO IBMB_ARCHIVE_AUDIT (TBL_NAME, RECOUNT, STATUS,ERR_TEXT) VALUES ('NOTIFICATION',reccount,'1',lc_out);
                COMMIT;
            END IF;
            EXIT WHEN c_archiveData%NOTFOUND;
        EXCEPTION
            WHEN OTHERS
            THEN
                ROLLBACK;
                lc_out := lc_out || 'Error:' || SQLERRM;
				totalRecords := totalRecords - reccount;
                INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('NOTIFICATION',reccount,'0',lc_out);
                COMMIT;
        END;
	END LOOP;
	CLOSE c_archiveData;
	INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('NOTIFICATION',totalRecords,'1','JOB_COMPLETED');
    COMMIT;

END ARCHVICE_NOTIFICATION;

PROCEDURE ARCHVICE_PUSH_NOTI_AUDIT 
   IS
    CURSOR c_archiveData IS
		SELECT * FROM IBMBUSER.PUSH_NOTIFICATION_AUDIT@ARCH_CIDB_IBMB WHERE CREATION_DATE <= add_months(sysdate, -3);
    TYPE t_data IS TABLE OF  c_archiveData%ROWTYPE;
	chunk_size CONSTANT INTEGER :=100000;
	l_data t_data;
	lc_out  VARCHAR2(512);
    reccount NUMBER; 
	totalRecords NUMBER;	
  BEGIN
    totalRecords := 0;
	OPEN c_archiveData;
	LOOP
        BEGIN
            FETCH c_archiveData BULK COLLECT INTO l_data LIMIT chunk_size;
            reccount := l_data.COUNT;
			totalRecords := totalRecords + reccount;
            FORALL i IN 1..reccount
                INSERT INTO IBMBARCHIVE.PUSH_NOTI_AUDIT_ARCHIVE(ID, SEGMENT_ID, CAMPAIGN_ID, DEVICE_ID,CREATION_DATE, NOTIFIED_DATE, STATUS, ERROR_CODE, ERROR_DESC, CIF, CIN,TITTLE,MESSAGE,
                ACTION,ACTION_URL,SOURCE_TYPE,PARENT_ID,TOKEN,EVENT_TYPE,LOCALE, ANDROID_IMAGE, IOS_MEDIA, DEVICE_TYPE)
                VALUES (l_data(i).ID,l_data(i).SEGMENT_ID,l_data(i).CAMPAIGN_ID,l_data(i).DEVICE_ID,l_data(i).CREATION_DATE,l_data(i).NOTIFIED_DATE,l_data(i).STATUS,l_data(i).ERROR_CODE,l_data(i).ERROR_DESC,
                l_data(i).CIF,l_data(i).CIN,l_data(i).TITTLE,l_data(i).MESSAGE,l_data(i).ACTION,l_data(i).ACTION_URL,l_data(i).SOURCE_TYPE,l_data(i).PARENT_ID,l_data(i).TOKEN,l_data(i).EVENT_TYPE,l_data(i).LOCALE,l_data(i).ANDROID_IMAGE,l_data(i).IOS_MEDIA,l_data(i).DEVICE_TYPE);
            lc_out := 'INS';
            FOR i IN 1..reccount
			 LOOP
                 DELETE FROM IBMBUSER.PUSH_NOTIFICATION_AUDIT@ARCH_CIDB_IBMB WHERE ID = l_data(i).ID;
		     END LOOP;
            lc_out := lc_out || '-DEL-';
            IF SQL%FOUND THEN
                lc_out := lc_out || 'SUCCESS';
                INSERT INTO ibmb_archive_audit (TBL_NAME, RECOUNT, STATUS,ERR_TEXT) VALUES ('PUSH_NOTIFICATION_AUDIT',reccount,'1',lc_out);
                COMMIT;
            END IF;
            EXIT WHEN c_archiveData%NOTFOUND;
        EXCEPTION
            WHEN OTHERS
            THEN
                ROLLBACK;
				totalRecords := totalRecords - reccount;
                lc_out := lc_out || 'Error:' || SQLERRM;
                INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('PUSH_NOTIFICATION_AUDIT',reccount,'0',lc_out);
                COMMIT;
        END;
	END LOOP;
	CLOSE c_archiveData;
	INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('PUSH_NOTIFICATION_AUDIT',totalRecords,'1','JOB_COMPLETED');
    COMMIT;

END ARCHVICE_PUSH_NOTI_AUDIT;

PROCEDURE ARCHVICE_SEGMENT_UPLOAD_FILE
   IS
      reccount      NUMBER;
      lc_out        VARCHAR2(512);
   BEGIN

       SELECT COUNT(1) INTO reccount FROM IBMBUSER.SEGMENT_UPLOAD_FILE@ARCH_CIDB_IBMB WHERE UPLOADED_DATE <= add_months(sysdate, -6);

       INSERT INTO IBMBARCHIVE.SEGMENT_UPLOAD_FILE_ARCHIVE SELECT * FROM IBMBUSER.SEGMENT_UPLOAD_FILE@ARCH_CIDB_IBMB WHERE UPLOADED_DATE <= add_months(sysdate, -6);
       lc_out := 'INS';
       IF reccount = SQL%ROWCOUNT THEN
         DELETE FROM IBMBUSER.SEGMENT_UPLOAD_FILE@ARCH_CIDB_IBMB WHERE UPLOADED_DATE <= add_months(sysdate, -6);
         lc_out := lc_out || '-DEL-';
         IF SQL%FOUND THEN
           lc_out := lc_out || 'SUCCESS';
           INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS,ERR_TEXT )  VALUES('SEGMENT_UPLOAD_FILE',reccount,'1',lc_out);
           COMMIT;
         END IF;
       END IF;
	   INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS,ERR_TEXT )  VALUES('SEGMENT_UPLOAD_FILE',reccount,'1','JOB_COMPLETED');
       COMMIT;

   EXCEPTION
      WHEN OTHERS
      THEN
         ROLLBACK;
         lc_out := lc_out || 'Error:' || SQLERRM;
         INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('SEGMENT_UPLOAD_FILE',reccount,'0',lc_out);
         COMMIT;
   END ARCHVICE_SEGMENT_UPLOAD_FILE;

PROCEDURE ARCHVICE_PAGE_VIEW_REPORT
   IS
    CURSOR c_archiveData IS
		SELECT * FROM IBMBUSER.PAGE_VIEW_REPORT@ARCH_CIDB_IBMB WHERE TRUNC(CREATION_TIME) <= TRUNC(sysdate -1);
    TYPE t_data IS TABLE OF  c_archiveData%ROWTYPE;
	chunk_size CONSTANT INTEGER :=200000;
	l_data t_data;
	lc_out  VARCHAR2(512);
    reccount NUMBER;
	totalRecords NUMBER;

   BEGIN
    totalRecords := 0;
	OPEN c_archiveData;
	LOOP
        BEGIN
            FETCH c_archiveData BULK COLLECT INTO l_data LIMIT chunk_size;
            reccount := l_data.COUNT;
			totalRecords := totalRecords + reccount;
            FORALL i IN 1..reccount
                INSERT INTO IBMBARCHIVE.PAGE_VIEW_REPORT_ARCHIVE(ID, CIF,CIN,CHANNEL_ID,PAGE,CREATION_TIME,RC,IP,HOSTNAME,COMPLETION_TIME,API_STATUS,API_ERRORCODE,HTTP_STATUS,HTTP_ERRORCODE,HTTP_ERRORDESC,REMOTE_IP) 
				VALUES (l_data(i).ID, l_data(i).CIF,l_data(i).CIN,l_data(i).CHANNEL_ID,l_data(i).PAGE,l_data(i).CREATION_TIME,l_data(i).RC,l_data(i).IP,l_data(i).HOSTNAME,l_data(i).COMPLETION_TIME,l_data(i).API_STATUS,l_data(i).API_ERRORCODE,l_data(i).HTTP_STATUS,l_data(i).HTTP_ERRORCODE,l_data(i).HTTP_ERRORDESC,l_data(i).REMOTE_IP); -- use columns name
            lc_out := 'INS';
            FOR i IN 1..reccount
			  LOOP
                 DELETE FROM IBMBUSER.PAGE_VIEW_REPORT@ARCH_CIDB_IBMB WHERE ID = l_data(i).ID;
			  END LOOP;
            lc_out := lc_out || '-DEL-';
            IF SQL%FOUND THEN
                lc_out := lc_out || 'SUCCESS';
                INSERT INTO ibmb_archive_audit (TBL_NAME, RECOUNT, STATUS,ERR_TEXT) VALUES ('PAGE_VIEW_REPORT',reccount,'1',lc_out);
                COMMIT;
            END IF;
            EXIT WHEN c_archiveData%NOTFOUND;
        EXCEPTION
            WHEN OTHERS
            THEN
                ROLLBACK;
                lc_out := lc_out || 'Error:' || SQLERRM;
				totalRecords := totalRecords - reccount;
                INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('PAGE_VIEW_REPORT',reccount,'0',lc_out);
                COMMIT;
        END;
	END LOOP;
	CLOSE c_archiveData;
	INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('PAGE_VIEW_REPORT',totalRecords,'1','JOB_COMPLETED');
    COMMIT;
END ARCHVICE_PAGE_VIEW_REPORT; 

PROCEDURE ARCHVICE_CA_REQUEST_AUDIT 
   IS
      reccount      NUMBER;
      lc_out        VARCHAR2(512);
   BEGIN

       SELECT COUNT(1) INTO reccount FROM IBMBUSER.CA_REQUEST_AUDIT@ARCH_CIDB_IBMB  WHERE  TRUNC(CREATE_DATE) <= TRUNC(sysdate -1);

       INSERT INTO IBMBARCHIVE.CA_REQUEST_AUDIT_ARCHIVE SELECT * FROM IBMBUSER.CA_REQUEST_AUDIT@ARCH_CIDB_IBMB WHERE TRUNC(CREATE_DATE) <= TRUNC(sysdate -1);
       lc_out := 'INS';
       IF reccount = SQL%ROWCOUNT THEN
         DELETE FROM IBMBUSER.CA_REQUEST_AUDIT@ARCH_CIDB_IBMB WHERE TRUNC(CREATE_DATE) <= TRUNC(sysdate -1);
         lc_out := lc_out || '-DEL-';
         IF SQL%FOUND THEN
           lc_out := lc_out || 'SUCCESS';
           INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS,ERR_TEXT )  VALUES('CA_REQUEST_AUDIT',reccount,'1',lc_out);
           COMMIT;
         END IF;
       END IF;
   EXCEPTION
      WHEN OTHERS
      THEN
         ROLLBACK;
         lc_out := lc_out || 'Error:' || SQLERRM;
         INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('CA_REQUEST_AUDIT',reccount,'0',lc_out);
         COMMIT;
   END ARCHVICE_CA_REQUEST_AUDIT;
   
   PROCEDURE ARCHIVE_CS_TRANSACTION_AUDIT
   IS
    CURSOR c_archiveData IS
		SELECT * FROM IBMBUSER.CS_TRANSACTION_AUDIT@ARCH_CIDB_IBMB WHERE TRUNC(CREATION_TIME) <= TRUNC(sysdate -3);
    TYPE t_data IS TABLE OF  c_archiveData%ROWTYPE;
	chunk_size CONSTANT INTEGER :=200000;
	l_data t_data;
	lc_out  VARCHAR2(512);
    reccount NUMBER;
	totalRecords NUMBER;

   BEGIN
    totalRecords := 0;
	OPEN c_archiveData;
	LOOP
        BEGIN
            FETCH c_archiveData BULK COLLECT INTO l_data LIMIT chunk_size;
            reccount := l_data.COUNT;
			totalRecords := totalRecords + reccount;
            FORALL i IN 1..reccount
                INSERT INTO IBMBARCHIVE.CS_TRANSACTION_AUDIT_ARCHIVE(CONVID,SESSIONID,RC,CIN,CIF,STATUS,CHANNEL,CREATION_TIME,PATH,TRANSACTION_ID,TRANSACTION_TYPE,RESULT,REQUIREMENT_ID,DECISION_ID,DECISION,REQUEST_AUTHENTICATOR,RESPONSE_AUTHENTICATOR,MESSAGE,SDK_ERROR_CODE,SDK_ERROR_MESSAGE,ID,MODIFY_DATE,APP_VERSION)
				VALUES (l_data(i).CONVID, l_data(i).SESSIONID,
				l_data(i).RC,l_data(i).CIN,l_data(i).CIF,l_data(i).STATUS,l_data(i).CHANNEL,l_data(i).CREATION_TIME,l_data(i).PATH,l_data(i).TRANSACTION_ID,l_data(i).TRANSACTION_TYPE,l_data(i).RESULT,l_data(i).REQUIREMENT_ID,l_data(i).DECISION_ID,l_data(i).DECISION,l_data(i).REQUEST_AUTHENTICATOR,l_data(i).RESPONSE_AUTHENTICATOR,l_data(i).MESSAGE,l_data(i).SDK_ERROR_CODE,l_data(i).SDK_ERROR_MESSAGE,l_data(i).ID,l_data(i).MODIFY_DATE,l_data(i).APP_VERSION); -- use columns name
            lc_out := 'INS';
            FOR i IN 1..reccount
			  LOOP
                 DELETE FROM IBMBUSER.CS_TRANSACTION_AUDIT@ARCH_CIDB_IBMB WHERE ID = l_data(i).ID;
			  END LOOP;
            lc_out := lc_out || '-DEL-';
            IF SQL%FOUND THEN
                lc_out := lc_out || 'SUCCESS';
                INSERT INTO ibmb_archive_audit (TBL_NAME, RECOUNT, STATUS,ERR_TEXT) VALUES ('CS_TRANSACTION_AUDIT',reccount,'1',lc_out);
                COMMIT;
            END IF;
            EXIT WHEN c_archiveData%NOTFOUND;
        EXCEPTION
            WHEN OTHERS
            THEN
                ROLLBACK;
                lc_out := lc_out || 'Error:' || SQLERRM;
				totalRecords := totalRecords - reccount;
                INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('CS_TRANSACTION_AUDIT',reccount,'0',lc_out);
                COMMIT;
        END;
	END LOOP;
	CLOSE c_archiveData;
	INSERT INTO IBMB_ARCHIVE_AUDIT(TBL_NAME, RECOUNT, STATUS, ERR_TEXT)  VALUES('CS_TRANSACTION_AUDIT',totalRecords,'1','JOB_COMPLETED');
    COMMIT;
    END ARCHIVE_CS_TRANSACTION_AUDIT;

END;

/

commit;


--------------------------------
Yes, you can set multiple email addresses in the os.environ['TO_ADDRESS'] field and modify the send_mail function to handle multiple recipients. You can store multiple email addresses in the TO_ADDRESS environment variable separated by a delimiter (e.g., comma) and then split this string into a list in the function.

Here’s how you can modify your function:

Store multiple email addresses in the TO_ADDRESS environment variable, separated by commas.
Split the TO_ADDRESS string into a list inside the function.

import os
import json
import uuid
from datetime import datetime
import httpx

# Method is used to send email
def send_mail(csv_data_in_bytes, s3_file_name):
    if csv_data_in_bytes is not None:
        currectDate = datetime.now().date()
        email_subject = "Sanctioned country report_" + currectDate.strftime("%Y-%m-%d")
        split_array = s3_file_name.split('/')
        s3_file_name=split_array[-1]
        s3_file_name = s3_file_name.replace(':','_')
        url = os.environ['SEND_EMAIL_SERVICE_URL']
        headers = {'XREF': str(uuid.uuid4()), 'CHANNELID': 'AWS', 'content-type': 'application/json'}

        # Split the TO_ADDRESS environment variable into a list of email addresses
        to_address_list = os.environ['TO_ADDRESS'].split(',')

        data = {
            "sourceSystem": "FAB",
            "requestID": str(uuid.uuid4()),
            "fromAddress": "noreply@bankfab.com",
            "entityName": "FAB",
            "toAddress": to_address_list,
            "emailSubject": email_subject,
            "emailBodyContent": "",
            "emailBodyContentType": "TEXT",
            "attachment": [{
                "attachementBytes": str(csv_data_in_bytes.decode("utf-8")),
                "mimeType": "application/csv",
                "fileName": s3_file_name
            }]
        }

        data = json.dumps(data)
        response = httpx.post(url, headers=headers, data=data, verify=sslcontext)
        if response.status_code == 200:
            logger.info("Email sent successfully")
        else:
            logger.info(f"Failed to send email. Status code: {response.status_code}")
        logger.info(f'Email API Response: {response.text}')
    else:
        logger.info("csv_data_in_bytes is null.")


-- Adding indexes
CREATE INDEX IDX_MOBILE_DEVICE_ID ON IBMBUSER.WATCH_REGISTRATION_DETAILS (MOBILE_DEVICE_ID);
CREATE INDEX IDX_WATCH_DEVICE_ID ON IBMBUSER.WATCH_REGISTRATION_DETAILS (WATCH_DEVICE_ID);
CREATE INDEX IDX_CIF ON IBMBUSER.WATCH_REGISTRATION_DETAILS (CIF);
CREATE INDEX IDX_CIN ON IBMBUSER.WATCH_REGISTRATION_DETAILS (CIN);


1. All the Npss related functionality needs to be disabled.
    IPP: Enable IPP Account to Account transfer for MB
    IPP: Enable IPP Account to Account transfer for IB
    NPSS Aani Overlay Roll out Enable(Y)/Disable(N)

2. DB Migration scripts needs to be executed by optimus team

3. Stop G42 Services all 4 services	
     npss-sca
	 npss-enrollment
	 npss-payment
	 npss-notification

try (CSVReader reader = new CSVReader(new StringReader(str))) {
            return reader.readAll().stream()
                .map(this::createSegmentUploadData)
                .collect(Collectors.toList());
        } catch (IOException | CsvValidationException e) {
            throw new AppException(ErrorCodes.SYS_INTERNAL_ERROR, e);
        }

private SegmentUploadData createSegmentUploadData(String[] record) {
        SegmentUploadData uploadData = new SegmentUploadData();

        for (int index = 0; index < record.length; index++) {
            String field = record[index];
            validateField(field);

            switch (index) {
                case 0:
                    uploadData.setData(field.replace("\"", ""));
                    if (uploadData.getData().length() > 100) {
                        log("length is greater than 100");
                        throw new AppException(ErrorCodes.INCORRECT_SEGMENT_DATA);
                    }
                    break;
                case 1:
                    uploadData.setAttr1(field);
                    break;
                case 2:
                    uploadData.setAttr2(field);
                    break;
                case 3:
                    uploadData.setAttr3(field);
                    break;
                case 4:
                    uploadData.setAttr4(field);
                    break;
                case 5:
                    uploadData.setAttr5(field);
                    break;
                case 6:
                    uploadData.setAttr6(field);
                    break;
                case 7:
                    uploadData.setAttr7(field);
                    break;
                default:
                    break;
            }
        }
        return uploadData;
    }


3605561,"1,000"
Invalid char between encapsulated token and delimiter at line: 1, position: 16
try (CSVParser parser = CSVParser.parse(new StringReader(str), format)) {
            for (CSVRecord record : parser) {
                SegmentUploadData uploadData = new SegmentUploadData();

                for (int index = 0; index < record.size(); index++) {
                    String field = record.get(index);
                    validateField(field);

                    switch (index) {
                        case 0:
                            uploadData.setData(field.replace("\"", ""));
                            if (uploadData.getData().length() > 100) {
                                log("length is greater than 100");
                                throw new AppException(ErrorCodes.INCORRECT_SEGMENT_DATA);
                            }
                            break;
                        case 1:
                            uploadData.setAttr1(field);
                            break;
                        case 2:
                            uploadData.setAttr2(field);
                            break;
                        case 3:
                            uploadData.setAttr3(field);
                            break;
                        case 4:
                            uploadData.setAttr4(field);
                            break;
                        case 5:
                            uploadData.setAttr5(field);
                            break;
                        case 6:
                            uploadData.setAttr6(field);
                            break;
                        case 7:
                            uploadData.setAttr7(field);
                            break;
                        default:
                            break;
                    }
                }
                segmentUploadData.add(uploadData);
            }
        } catch (IOException e) {
            throw new AppException(ErrorCodes.SYS_INTERNAL_ERROR, e);
        }



<dependency>
        <groupId>org.apache.commons</groupId>
        <artifactId>commons-io</artifactId>
        <version>2.11.0</version>
    </dependency>

        at org.apache.commons.csv.CSVParser$CSVRecordIterator.getNextRecord(CSVParser.java:149)
	at org.apache.commons.csv.CSVParser$CSVRecordIterator.hasNext(CSVParser.java:158)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:132)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)
	at com.fab.pb.helpers.pdfprocessor.PdfHelper.main(PdfHelper.java:348)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.io.function.Uncheck
<dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-csv</artifactId>
    <version>1.11.0</version>
</dependency>

List<SegmentUploadData> segmentUploadData = new ArrayList<>();

    CSVFormat format = CSVFormat.DEFAULT.withQuote('"');

    try (CSVParser parser = CSVParser.parse(new StringReader(str), format)) {
        segmentUploadData = StreamSupport.stream(parser.spliterator(), false)
            .map(record -> {
                SegmentUploadData uploadData = new SegmentUploadData();
    
                for (int index = 0; index < record.size(); index++) {
                    switch (index) {
                        case 0:
                            uploadData.setData(record.get(0).replace("\"", ""));
                            if (uploadData.getData().length() > 100) {
                                log.info("length is greater than 100");
                                throw new AppException(ErrorCodes.INCORRECT_SEGMENT_DATA);
                            }
                            break; // Added break

                        case 1:
                            uploadData.setAttr1(record.get(1));
                            break;
                        case 2:
                            uploadData.setAttr2(record.get(2));
                            break;
                        case 3:
                            uploadData.setAttr3(record.get(3));
                            break;
                        case 4:
                            uploadData.setAttr4(record.get(4));
                            break;
                        case 5:
                            uploadData.setAttr5(record.get(5));
                            break;
                        case 6:
                            uploadData.setAttr6(record.get(6));
                            break;
                        case 7:
                            uploadData.setAttr7(record.get(7));
                            break;
                        default:
                            break;
                    }
                }

                return uploadData;
            })
            .collect(Collectors.toList());
    }

List<SegmentUploadData> segmentUploadData = new ArrayList<SegmentUploadData>();
			String[] splitted = Arrays.stream(str.split("\n")).map(String::trim).toArray(String[]::new);
			List<String> list = Arrays.asList(splitted);

			for (String lineStr : list) {
				//String[] line = Arrays.stream(lineStr.split(",")).map(String::trim).toArray(String[]::new);
				String[] line = parseCsvLine(lineStr);
				if(ArrayUtils.isNotEmpty(line)) {
				  List<String> splittedLine = Arrays.asList(line);
				  SegmentUploadData uploadData = new SegmentUploadData();
				  for(int index=0;index<splittedLine.size();index++){
					switch(index){
					case 0:
						uploadData.setData(splittedLine.get(0).replace("\"", ""));
						// PRM-2709: FAB_Admin_Elig_file_seg_file_upload_issue with incorrect CIN
						if(uploadData.getData().length()>100) {
							log.info("length is greater than 100");
							throw new AppException(ErrorCodes.INCORRECT_SEGMENT_DATA);
						}
						break;
					case 1:
						uploadData.setAttr1(splittedLine.get(1));
						break;
					case 2:
						uploadData.setAttr2(splittedLine.get(2));
						break;
					case 3:
						uploadData.setAttr3(splittedLine.get(3));
						break;
					case 4:
						uploadData.setAttr4(splittedLine.get(4));
						break;
					case 5:
						uploadData.setAttr5(splittedLine.get(5));
						break;
					case 6:
						uploadData.setAttr6(splittedLine.get(6));
						break;
					case 7:
						uploadData.setAttr7(splittedLine.get(7));
						break;
					default:
						break;
					}
				}
				segmentUploadData.add(uploadData);
			  }
			}


1)Callsign whitelisted the mw risk endpoint: https://kproxy-uat.risk-middleware-dev.aeapps.bankfab.com/ae/core/sim-swap/v1/sim/swap/status  from Akhaya and after we have trigger the etg reqyest and mw team given us the req/res and we repoted to team  
 
 
below is the update:
We worked with CALLSIGN and KONG team to stabilize the environment.
Post that able to generate logs from middleware team. Below are the logs
Naveen Gupta please check. If any support required connect with us Thanks Sanjib Mohanty
Jun 21, 2024 @ 14:33:44.244	trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5, simSwapStatus	INFO	Service Request: {"applicationArea":{"transactionId":"trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5"}}

Jun 21, 2024 @ 14:33:44.249	trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5, simSwapStatus	INFO	Service Response: 400 BAD_REQUEST {"applicationArea":{"transactionId":"trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5"},"responseStatus":{"status":"ERROR","errorDetails":[{"errorCode":"GEN8003","errorDesc":"Missing Mandatory fields in Request payload"}]}}
 
 
 
2) After changing the request payload fromat by callsign :   "transaction": {
                    "additionalTransactionInformation": {
                        "channel": "MOB",
                        "phoneNumber": "0504972291",
                        "countryOfOrigin": "AE",
                        "transactionDateTime": "2024-06-21T09:00:45.043Z",
                        "referenceDate": "2024-06-21 03:12:02.751"
                    }
                } 
				Still callsign request is not recieved in mw and they are saying the request is invalid josn format that is why they r not able to provide request 
3)https://kproxy-uat.risk-middleware-dev.aeapps.bankfab.com/ae/core/sim-swap/v1/sim/swap/status   ---------its not working from postman as Etislat connectivity  issue As per Prasant

Update on Middleware Risk Endpoint Whitelisting and Logging:

1. Whitelisting and Initial Triggering:
Callsign has successfully whitelisted the middleware risk endpoint: https://kproxy-uat.risk-middleware-dev.aeapps.bankfab.com/ae/core/sim-swap/v1/sim/swap/status from Akhaya. Following this, we triggered the ETG request, and the middleware team provided us with the request and response details, which we have reported to the team.

Update:
We collaborated with the CALLSIGN and KONG teams to stabilize the environment. Subsequently, we were able to generate logs from the middleware team. Below are the logs:

Naveen Gupta, please review the logs. If any support is required, please connect with us.

Logs:

Timestamp: Jun 21, 2024 @ 14:33:44.244

Transaction ID: trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5

Service: simSwapStatus

Log Level: INFO

Service Request: {"applicationArea":{"transactionId":"trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5"}}

Timestamp: Jun 21, 2024 @ 14:33:44.249

Transaction ID: trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5

Service: simSwapStatus

Log Level: INFO

Service Response: 400 BAD_REQUEST {"applicationArea":{"transactionId":"trn-p2kg9mwp-0sps3t5r-9ncf25tma-4psbcgd5"},"responseStatus":{"status":"ERROR","errorDetails":[{"errorCode":"GEN8003","errorDesc":"Missing Mandatory fields in Request payload"}]}}

2. Payload Format Update:
After modifying the request payload format by Callsign, the updated structure is as follows:

json
Copy code
{
    "transaction": {
        "additionalTransactionInformation": {
            "channel": "MOB",
            "phoneNumber": "0504972291",
            "countryOfOrigin": "AE",
            "transactionDateTime": "2024-06-21T09:00:45.043Z",
            "referenceDate": "2024-06-21 03:12:02.751"
        }
    }
}
Despite this modification, Callsign's request is still not being received by the middleware, and they have indicated that the request is in an invalid JSON format, preventing them from providing the request.

3. Connectivity Issue:
The endpoint https://kproxy-uat.risk-middleware-dev.aeapps.bankfab.com/ae/core/sim-swap/v1/sim/swap/status is currently not functioning from Postman due to connectivity issues with Etisalat, as reported by Prasant.

return getWebClient(finalUrl, false).method(httpMethod).uri(finalUrl)
				.headers(header -> header.putAll(headers)).body(BodyInserters.fromValue(xmlRequest))
				.exchangeToMono(clientResponse -> processResponse(serviceName, finalUrl, headers, t1, clientResponse))
				.contextCapture()
				.retryWhen(Retry.backoff(3, Duration.ofMillis(500))
					            .filter(this::isRetryRequired));


/**
	 * Method to invoke Post and PUT API's without proxy.
	 * 
	 * @param <T>
	 * @param serviceName
	 * @param url
	 * @param httpMethod
	 * @param pathParams
	 * @param requestObj
	 * @param headersMap
	 * @param queryParams
	 * @return
	 */
	public <T> Mono<ConnectorResponse> invokePostPut(String serviceName, String url, HttpMethod httpMethod,
			Map<String, String> pathParams, T requestObj, Map<String, String> headersMap, String... queryParams) {

		String finalUrl = checkNgetServiceUrl(url, pathParams, headersMap, queryParams);
		
		String request = "{}";
		if (Objects.nonNull(requestObj)) {
			request = JsonUtils.convertToJsonUsingGson(requestObj);
		}
		
		HttpHeaders headers = getHttpHeaders(serviceName, finalUrl, httpMethod, headersMap, MediaType.APPLICATION_JSON);
		log.info("XREF: {}, Request: {}", headers.getFirst(BaseAppConstants.XREF), TextUtils.maskJsonFields(request));
		long t1 = System.currentTimeMillis();

		return getWebClient(finalUrl, false).method(httpMethod).uri(finalUrl)
				.headers(header -> header.putAll(headers)).body(BodyInserters.fromValue(request))
				.exchangeToMono(clientResponse -> processResponse(serviceName, finalUrl, headers, t1, clientResponse))
				.contextCapture();




3605561,"1,000"
3189338,"1,000"
5734543,"1,000"
4116175,"1,000"
1074462,"1,000"
4676587,1000
import org.apache.commons.lang3.StringUtils;

private String[] parseCsvLine(String line) {
    List<String> result = new ArrayList<>();
    boolean inQuotes = false;
    StringBuilder current = new StringBuilder();

    for (char c : line.toCharArray()) {
        if (c == '"') {
            inQuotes = !inQuotes;
        } else if (c == ',' && !inQuotes) {
            result.add(current.toString());
            current = new StringBuilder();
        } else {
            current.append(c);
        }
    }
    result.add(current.toString());

    String[] parsedLine = result.toArray(new String[0]);

    // Validate second column if present
    if (parsedLine.length > 1) {
        String secondColumn = StringUtils.strip(parsedLine[1], "\"").trim();
        if (!isValidSecondColumn(secondColumn)) {
            return StringUtils.EMPTY_STRING_ARRAY;
        }
    } else {
        return StringUtils.EMPTY_STRING_ARRAY;
    }

    // Validate first column
    String firstColumn = StringUtils.strip(parsedLine[0], "\"").trim();
    if (StringUtils.isEmpty(firstColumn)) {
        return StringUtils.EMPTY_STRING_ARRAY;
    }

    return parsedLine;
}

private boolean isValidSecondColumn(String column) {
    // Your validation logic for the second column goes here
    // Example: Check if it's numeric with commas and dots
    return column.matches("[0-9,.]+");
}
/**
	 * Method to create segment for file upload.
	 * 
	 * @param segementRequest
	 * @return
	 */
	public CreatePinpointResponse uploadSegment(Segment segementRequest) {
		CreatePinpointResponse response = new CreatePinpointResponse();
		return execute(segementRequest, response, req -> {
			if(StringUtils.isBlank(req.getSegmentName()) || Objects.isNull(req.getSegmentType()) 
					|| StringUtils.isBlank(req.getFileContentsAsBase64()) || StringUtils.isBlank(req.getFileName())) {
				throw new AppException(ErrorCodes.SYS_INVALID_REQUEST);
			}
			if(pinpointRepository.checkIfSegmentExists(segementRequest.getSegmentName())){
				throw new AppException(ErrorCodes.SEGMENT_NAME_ALREADY_EXIST);
			}
			byte[] inBytes = Base64.decodeBase64(req.getFileContentsAsBase64().getBytes());
						
			String str = new String(inBytes);

			if (StringUtils.isBlank(str.trim())) {
				throw new AppException(ErrorCodes.SYS_INVALID_REQUEST);
			}

			List<SegmentUploadData> segmentUploadData = new ArrayList<SegmentUploadData>();
			String[] splitted = Arrays.stream(str.split("\n")).map(String::trim).toArray(String[]::new);
			List<String> list = Arrays.asList(splitted);

			for (String lineStr : list) {
				String[] line = Arrays.stream(lineStr.split(",")).map(String::trim).toArray(String[]::new);
				List<String> splittedLine = Arrays.asList(line);
				SegmentUploadData uploadData = new SegmentUploadData();
				for(int index=0;index<splittedLine.size();index++){
					switch(index){
					case 0:
						uploadData.setData(splittedLine.get(0).replace("\"", ""));
						// PRM-2709: FAB_Admin_Elig_file_seg_file_upload_issue with incorrect CIN
						if(uploadData.getData().length()>100) {
							log.info("length is greater than 100");
							throw new AppException(ErrorCodes.INCORRECT_SEGMENT_DATA);
						}
						break;
					case 1:
						uploadData.setAttr1(splittedLine.get(1));
						break;
					case 2:
						uploadData.setAttr2(splittedLine.get(2));
						break;
					case 3:
						uploadData.setAttr3(splittedLine.get(3));
						break;
					case 4:
						uploadData.setAttr4(splittedLine.get(4));
						break;
					case 5:
						uploadData.setAttr5(splittedLine.get(5));
						break;
					case 6:
						uploadData.setAttr6(splittedLine.get(6));
						break;
					case 7:
						uploadData.setAttr7(splittedLine.get(7));
						break;
					default:
						break;
					}
				}
				segmentUploadData.add(uploadData);
			}
			
			String segmentID = UUID.randomUUID().toString();
			req.setCreateMode("UPLOAD");
			req.setRecordCount(segmentUploadData.size());
			int count = pinpointRepository.insertToSegment(req, segmentID);
			log.info("Segment created with id :{}", segmentID);
			if(count > 0) {
				//upload the file to new table.
				pinpointRepository.uploadSegmentBatch(segmentUploadData,segmentID, req );
				//Arrays.asList(parts).stream().forEach(record -> pinpointRepository.uploadSegment(record, segmentID, req));
			}
			response.setSegmentId(segmentID);
			return response;
		});
	}


import org.apache.commons.lang3.StringUtils;

private String[] parseCsvLine(String line) {
    List<String> result = new ArrayList<>();
    boolean inQuotes = false;
    StringBuilder current = new StringBuilder();

    for (char c : line.toCharArray()) {
        if (c == '"') {
            inQuotes = !inQuotes;
        } else if (c == ',' && !inQuotes) {
            result.add(current.toString());
            current = new StringBuilder();
        } else {
            current.append(c);
        }
    }
    result.add(current.toString());

    String[] parsedLine = result.toArray(new String[0]);

    // Validate second column if present
    if (parsedLine.length > 1) {
        String secondColumn = StringUtils.strip(parsedLine[1], "\"").trim();
        if (!isValidSecondColumn(secondColumn)) {
            return StringUtils.EMPTY_STRING_ARRAY;
        }
    } else {
        return StringUtils.EMPTY_STRING_ARRAY;
    }

    // Validate first column
    String firstColumn = StringUtils.strip(parsedLine[0], "\"").trim();
    if (StringUtils.isEmpty(firstColumn)) {
        return StringUtils.EMPTY_STRING_ARRAY;
    }

    return parsedLine;
}

private boolean isValidSecondColumn(String column) {
    // Your validation logic for the second column goes here
    // Example: Check if it's numeric with commas and dots
    return column.matches("[0-9,.]+");
}
private boolean isNumericWithCommaAndDot(String str) {
    return str.matches("[0-9,.]+");
}
And here are the updated unit tests:

java
Copy code
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.*;

public class SegmentUploaderTest {

    SegmentUploader segmentUploader = new SegmentUploader();

    @Test
    public void testParseCsvLine_WithCommasInQuotes() {
        String line = "3605561,\"1,000\"";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"3605561", "1,000"}, result);
    }

    @Test
    public void testParseCsvLine_WithDotsInQuotes() {
        String line = "3605561,\"1.000\"";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"3605561", "1.000"}, result);
    }

    @Test
    public void testParseCsvLine_WithCommasAndDotsInQuotes() {
        String line = "3605561,\"1,000.00\"";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"3605561", "1,000.00"}, result);
    }

    @Test
    public void testParseCsvLine_WithoutQuotes() {
        String line = "4676587,1000";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"4676587", "1000"}, result);
    }

    @Test
    public void testParseCsvLine_WithMultipleColumns() {
        String line = "3605561,\"1,000\",test,\"data,with,commas\"";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"3605561", "1,000", "test", "data,with,commas"}, result);
    }

    @Test
    public void testParseCsvLine_WithEmptyFields() {
        String line = "3605561,\"\",,";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }

    @Test
    public void testParseCsvLine_WithNonNumericSecondColumn() {
        String line = "3605561,\"nonNumeric\"";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }

    @Test
    public void testParseCsvLine_WithInvalidCharactersInSecondColumn() {
        String line = "3605561,\"1,000a\"";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }

    @Test
    public void testParseCsvLine_WithMismatchedQuotes() {
        String line = "3605561,\"1,000";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }

    @Test
    public void testParseCsvLine_WithExtraCommas() {
        String line = "3605561,\"1,000\",,,";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{"3605561", "1,000", "", "", ""}, result);
    }

    @Test
    public void testParseCsvLine_WithNoData() {
        String line = "";
        String[] result = segmentUploader.parseCsvLine(line);
        assertArrayEquals(new String[]{""}, result);
    }

    @Test
    public void testParseCsvLine_WithNonNumericDataInSecondColumn() {
        String line = "3605561,notNumeric";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }

    @Test
    public void testParseCsvLine_WithQuotedCommasInSecondColumn() {
        String line = "3605561,\"data,with,commas\"";
        assertThrows(IllegalArgumentException.class, () -> segmentUploader.parseCsvLine(line));
    }
}

private void prepareAcctLoanDeposits(CustPositionResponse custPosition, CustomerProducts customerFavouriteProducts, CustomerProducts customerProducts, FeaturePromotion featurePromotion,
        Map<String, ProductPreference> userPreferences) {
    // sort accounts in customer position accounts by sorting order of Account types
    sortAccountsByAccountType(custPosition);
    List<AccountDetails> acctDetails = custPosition.getListOfAccounts();
    
    if (acctDetails != null && !acctDetails.isEmpty()) {
        for (AccountDetails acctDtl : acctDetails) {
            // Decide whether to show on dashboard
            if (isLoanAccountCode(acctDtl.getAccountType())) {
                if (!StringUtils.startsWithAny(acctDtl.getAccountNo(), SKIP_PD_LOANS)) {
                    Loan loan = getLoanData(acctDtl);
                    loan.setProduct(ProductTypes.LOAN.name());
                    
                    if (userPreferences.containsKey(loan.getLoanNumber())) {
                        ProductPreference prodPref = userPreferences.get(loan.getLoanNumber());
                        loan.setNickName(prodPref.getNickName());
                        loan.setDisplaySequence(prodPref.getDisplaySequence());
                        loan.setIsFavorite(prodPref.getIsFavorite());
                        loan.setIsHide(prodPref.getIsHide());
                        // Add all favorite products
                        if (prodPref.getIsFavorite()) {
                            customerFavouriteProducts.addLoan(loan);
                        }
                    } else {
                        loan.setDisplaySequence(0);
                    }
                    customerProducts.addLoan(loan);
                } else {
                    log.warn("#### Skipping PD loan from customer loan dashboard:{}", acctDtl.getAccountNo());
                }
            } else {
                // Skip deposit with HNI / ISL / NIF / ISB
                if (AccountType.TD.getCode().equals(acctDtl.getAccountType())) {
                    String accountId = acctDtl.getAccountNo();
                    if (StringUtils.startsWithAny(accountId, AppConstants.SKIP_PREFIX_DEPOSIT)) {
                        acctDtl.setAccountNo(accountId.substring(3));
                    }
                }
                Account acct = getAccountAndDepositData(acctDtl);
                
                if (userPreferences.containsKey(acct.getNumber())) {
                    ProductPreference prodPref = userPreferences.get(acct.getNumber());
                    acct.setNickName(prodPref.getNickName());
                    acct.setDisplaySequence(prodPref.getDisplaySequence());
                    acct.setIsFavorite(prodPref.getIsFavorite());
                    acct.setIsHide(prodPref.getIsHide());
                    acct.setIban(acctDtl.getIban());
                    // Add all favorite products
                    if (prodPref.getIsFavorite()) {
                        if (AccountType.TD.getCode().equals(acctDtl.getAccountType())) {
                            acct.setProduct(ProductTypes.DEPOSIT.name());
                            customerFavouriteProducts.addDeposit(acct);
                        } else {
                            acct.setProduct(ProductTypes.ACCOUNT.name());
                            customerFavouriteProducts.addAccount(acct);
                        }
                    }
                } else {
                    acct.setDisplaySequence(0);
                }
                
                // If iSave account to get the count to show on dashboard
                if (ProductCode.ISAVE.getCode().equals(acctDtl.getAccountCategoryCode())) {
                    acct.setAccountSubType("isave");
                    customerProducts.addIsave(acct);
                    customerProducts.addAccount(acct); // Adding Isave Account in account list after discussing with Pratik
                } else {
                    if (AccountType.TD.getCode().equals(acctDtl.getAccountType())) {
                        customerProducts.addDeposit(acct);
                    } else {
                        customerProducts.addAccount(acct);
                    }
                }
                
                if (Objects.nonNull(acctDtl.getDebitCards()) && !acctDtl.getDebitCards().isEmpty()) {
                    acctDtl.getDebitCards().stream().forEach(debitCard -> {
                        if (DateTimeHelper.INSTANCE.isFutureDate(debitCard.getExpirationDate(), DATE_DDMMYYYY)) {
                            if (DebitCardStatus.NEW_CARD.getCode().equals(debitCard.getCardStatus())) {
                                featurePromotion.addMaskedDcNumber(TextUtils.INSTANCE.maskCardNumber(debitCard.getDebitCardIdentifier(), AppConstants.MASK_CHARCTER));
                                if ("N".equalsIgnoreCase(debitCard.getCardDisplayIndicator())) {
                                    featurePromotion.incrementDebitCardCount();
                                }
                            }
                            if (AppConstants.DBT_CARD_ALLOWED_STATUS.contains(debitCard.getCardStatus())) {
                                Product product = new Product();
                                product.setLabel(TextUtils.INSTANCE.maskCardNumber(debitCard.getDebitCardIdentifier(), AppConstants.MASK_CHARCTER));
                                product.setProdRef(TextUtils.INSTANCE.getCardRef(debitCard.getDebitCardIdentifier()));
                                product.setStatus(DebitCardStatus.find(debitCard.getCardStatus()).getStatusDesc());
                                product.setProductType(ProductTypes.DEBIT);
                                product.setExpiryDate(DateTimeHelper.INSTANCE.formatDate(debitCard.getExpirationDate(), DATE_DDMMYYYY, DATE_MMYY));
                                if (Objects.nonNull(debitCard.getIssueDate()) && !debitCard.getIssueDate().isEmpty()) {
                                    product.setIssueDate(DateTimeHelper.INSTANCE.formatDate(debitCard.getIssueDate(), DATE_DDMMYYYY, DATE_MMYY));
                                } else {
                                    product.setIssueDate(debitCard.getIssueDate());
                                }
                                product.setDigitalCardIndicator(debitCard.getDigitalCardIndicator());
                                product.setVirtualCardIndicator(debitCard.getVirtualCardIndicator());
                                // product.setIssueDate(staticDataRepository.fetchStaticData_EN(VIRTUAL_DEBIT_CARD, ISSUE_DATE).getDescription());
                                // product.setDigitalCardIndicator(staticDataRepository.fetchStaticData_EN(VIRTUAL_DEBIT_CARD, DIGITAL_CARD_INDICATOR).getDescription());
                                // product.setVirtualCardIndicator(staticDataRepository.fetchStaticData_EN(VIRTUAL_DEBIT_CARD, VIRTUAL_CARD_INDICATOR).getDescription());
                                log.info("Virtual Debit card IssueDate, Digital", product.getIssueDate(), product.getVirtualCardIndicator(), product.getDigitalCardIndicator());
                                acct.addDebitCard(product);
                            }
                        }
                        
                        log.info("Debit Card Status " + DebitCardStatus.CARD_ACTIVE.getCode());
                        log.info("Debit Fetch Card Status " + debitCard.getCardStatus());
                        
                        if (DebitCardStatus.CARD_ACTIVE.getCode().equals(debitCard.getCardStatus())) {
                            if ("N".equalsIgnoreCase(debitCard.getCardDisplayIndicator())) {
                                featurePromotion.incrementActiveDebitCardCount();
                            }
                        }
                    });
                }
            }
        }
    } else {
        log.warn("Account:{} is not allowed on Dashboard View", acctDtl);
    }
}

kubectl cp <pod_name>:/var/kafka-ssl/abc.jks /local/path/abc.jks
kubectl exec -n <namespace> <pod_name> -- readlink -f /var/kafka-ssl/abc.jks

[root@g42uatlibmb1 npss]# kubectl exec -n npss npss-notifications-6467fb85db-4g5bq  -- readlink -f /var/ssl-store-kafka-ks/ibmb.keystore.uat.jks
/var/ssl-store-kafka-ks/..2024_06_24_07_46_23.547751902/ibmb.keystore.uat.jks
[root@g42uatlibmb1 npss]# kubectl cp npss-notifications-6467fb85db-4g5bq :..2024_06_24_07_46_23.547751902/ibmb.keystore.uat.jks /root/abc.jks
error: filespec must match the canonical format: [[namespace/]pod:]file/path
[root@g42uatlibmb1 npss]# kubectl cp npss-notifications-6467fb85db-4g5bq :/var/ssl-store-kafka-ks/..2024_06_24_07_46_23.547751902/ibmb.keystore.uat.jks  /root/abc.jks
error: filespec must match the canonical format: [[namespace/]pod:]file/path

kubectl cp npss/npss-notifications-6467fb85db-4g5bq:/var/ssl-store-kafka-ks/..2024_06_24_07_46_23.547751902/ibmb.keystore.uat.jks /root/abc.jks



String jsonString = "{"
    + "\"applicationArea\":{"
        + "\"countryOfOrigin\":\"AE\","
        + "\"senderId\":\"MOB\","
        + "\"transactionId\":\"A9f5243582a124a42bfa8fbe35e5db3e8\","
        + "\"transactionDateTime\":\"2024-XX-XXT04:01:04.004Z\","
        + "\"language\":\"EN\","
        + "\"creationDateTime\":\"22/Jun/2024 04:01:04\","
        + "\"requiredExecutionDate\":\"22/Jun/2024 04:01:04\""
    + "},"
    + "\"responseStatus\":{"
        + "\"status\":\"SUCCESS\","
        + "\"errorDetails\":[{"
            + "\"errorCode\":\"0\","
            + "\"errorDesc\":\"SUCCESS\""
        + "}]"
    + "},"
    + "\"common\":{"
        + "\"rateMode\":\"DBMODE\","
        + "\"rateReferenceNumber\":\"NA\""
    + "},"
    + "\"ratesResponse\":[{"
        + "\"buyCurrency\":\"USD\","
        + "\"sellCurrency\":\"AED\","
        + "\"buyingRate\":3.65779,"
        + "\"sellingRate\":3.68827,"
        + "\"dealtCurrency\":\"AED\","
        + "\"dealtAmount\":100.0,"
        + "\"status\":\"OK\","
        + "\"ccyPair\":\"USD.AED/S\","
        + "\"GMbuyingRate\":3.67248,"
        + "\"GMsellingRate\":3.67358,"
        + "\"GMbuyingMargin\":0,"
        + "\"GMsellingMargin\":0"
    + "}]"
+ "}";

22 Jun 2024 04:01:04,332 INFO (WebContainer : 31) (MOBILE-1000753765) [RequestInterceptor:]: Resource:/ft/mcsend/v1/fxrate/fetch, Request:{"amount":100.0,"fr
omCurrency":"AED","toCurrency":"PHP","transferCurrency":"AED","transferType":"P2P","txnRef":"f1db6b034aec4e44882ec1bbcf99d622"}

22 Jun 2024 04:01:04,332 INFO (WebContainer : 31) (MOBILE-1000753765) [RequestResolver:]: pathURL /ft/mcsend/v1/fxrate/fetch
22 Jun 2024 04:01:04,332 INFO (WebContainer : 31) (MOBILE-1000753765) [RequestResolver:]: rootPath:/ft
22 Jun 2024 04:01:04,332 INFO (WebContainer : 31) (MOBILE-1000753765) [RequestResolver:]: remainingPath:/mcsend/v1/fxrate/fetch
22 Jun 2024 04:01:04,341 INFO (WebContainer : 31) (MOBILE-1000753765) [FxRateSF:]: isNonUSDSettlement flag is :: false
22 Jun 2024 04:01:04,343 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: xref A9f5243582a124a42bfa8fbe35e5db3e8 | channelType "MOBILE"
22 Jun 2024 04:01:04,345 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: Connecting to URL:https://kproxy.risk-mw-pci-kong-prod.aeapps.bankfab
.com/ae/core/trapi/v1/exchange/rates, RequestType:POST, Headers:[{"name":"XXXX","value":"A9f5243582a124a42bfa8fbe35e5db3e8","elements":[{"name":"XXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXX","parameters":[],"parameterCount":0}]},{"name":"XXXXXXXX","value":"EN","elements":[{"name":"XX","parameters":[],"parameterCount":0}]},{
"name":"XXXXXXXXX","value":"MOB","elements":[{"name":"XXX","parameters":[],"parameterCount":0}]},{"name":"XXXXXXXXXXX","value":"87.200.21.97","elements":[{"n
ame":"XX.XXX.XX.XX","parameters":[],"parameterCount":0}]}]
22 Jun 2024 04:01:04,345 INFO (WebContainer : 31) (MOBILE-1000753765) [TextUtils:]: Masking special chars in log
22 Jun 2024 04:01:04,347 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: Http Request:{"rateObjectRequest":{"common":{"customerSegment":"IBMB.
MCSEND","valueDate":"2024-XX-XX","dealtCurrency":"AED","dealtAmount":100.0,"tenor":"SPOT","rateMode":"REALTIME","entity":"AE0XXXXX0001","daoCode":"1033X0100"
,"customerID":"1188110"},"rates":[{"buyCurrency":"USD","sellCurrency":"AED"}]},"applicationArea":{"countryOfOrigin":"AE","creationDateTime":"22/Jun/2024 04:0
1:04","requiredExecutionDate":"22/Jun/2024 04:01:04","senderId":"MOB","transactionDateTime":"2024-XX-XXT04:01:04.004Z","transactionId":"A9f5243582a124a42bfa8
fbe35e5db3e8","language":"EN"}}
22 Jun 2024 04:01:10,936 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: Status code 200
22 Jun 2024 04:01:10,936 INFO (WebContainer : 31) (MOBILE-1000753765) [TextUtils:]: Masking special chars in log
22 Jun 2024 04:01:10,938 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: Http Response:{"applicationArea":{"countryOfOrigin":"AE","senderId":"
MOB","transactionId":"A9f5243582a124a42bfa8fbe35e5db3e8","transactionDateTime":"2024-XX-XXT04:01:04.004Z","language":"EN","creationDateTime":"22/Jun/2024 04:
01:04","requiredExecutionDate":"22/Jun/2024 04:01:04"},"responseStatus":{"status":"SUCCESS","errorDetails":[{"errorCode":"0","errorDesc":"SUCCESS"}]},"common
":{"rateMode":"DBMODE","rateReferenceNumber":"NA"},"ratesResponse":[{"buyCurrency":"USD","sellCurrency":"AED","buyingRate":3.65779,"sellingRate":3.68827,"dea
ltCurrency":"AED","dealtAmount":100.0,"status":"OK","ccyPair":"USD.AED/S","GMbuyingRate":3.67248,"GMsellingRate":3.67358,"GMbuyingMargin":0,"GMsellingMargin"
:0}]}
22 Jun 2024 04:01:10,938 INFO (WebContainer : 31) (MOBILE-1000753765) [HttpConnector:]: Http request processed in :6595 msec for URL:https://kproxy.risk-mw-p
ci-kong-prod.aeapps.bankfab.com/ae/core/trapi/v1/exchange/rates
22 Jun 2024 04:01:10,939 INFO (WebContainer : 31) (MOBILE-1000753765) [FxRateServiceInvoker:]: API URL is : https://kproxy.risk-mw-pci-kong-prod.aeapps.bankf
ab.com/ae/core/trapi/v1/exchange/rates
22 Jun 2024 04:01:10,939 INFO (WebContainer : 31) (MOBILE-1000753765) [FxRateServiceInvoker:]: Handle 4XX errors in sf class..
22 Jun 2024 04:01:10,939 ERROR (WebContainer : 31) (MOBILE-1000753765) [ExceptionHandler:]: Handle null pointer exception for:java.lang.NullPointerException
22 Jun 2024 04:01:10,940 INFO (WebContainer : 31) (MOBILE-1000753765) [LocaleHelper:]: locale:en, code:SYS_DEFAULT_ERROR, text translation:We are unable to p
rocess your request right now. Please try again later.
22 Jun 2024 04:01:10,943 INFO (WebContainer : 31) (MOBILE-1000753765) [RequestInterceptor:]: Resource:/ft/mcsend/v1/fxrate/fetch response:{"result":{"status"
:"error","errorInfo":{"code":"SYS_DEFAULT_ERROR","desc":"We are unable to process your request right now. Please try again later. "}}}
22 Jun 2024 04:01:10,943 INFO (WebContainer : 31) (MOBILE-1000753765) [UserStatisticsSF:]: CIF ID in PageViewReport userID 10007X3765, convid ba461cb4f8e3448
a81baf93f48a3e2f5, url point /ft/mcsend/v1/fxrate/fetch::
22 Jun 2024 04:01:10,944 INFO (WebContainer : 31) (MOBILE-1000753765) [UserStatisticsSF:]: Page View Report {"cif":"10007X3765","cin":"1188110","channelType"
:"MOBILE","viewedPage":"/ft/mcsend/v1/fxrate/fetch","httpStatus":"SUCCESS","httpErrorCode":"0","httpErrorDesc":"SUCCESS","apiStatus":"error","apiErrorCode":"
SYS_DEFAULT_ERROR","rc":"A9f5243582a124a42bfa8fbe35e5db3e8","creationTime":1719014464062,"completionTime":1719014470943,"remoteIp":"87.200.21.97"} ::
22 Jun 2024 04:01:10,980 INFO (WebContainer : 31) (MOBILE-1000753765) [UserStatisticsSF:]: exiting publish2UserStatisticsQ method
22 Jun 2024 04:01:10,980 INFO (WebContainer : 31) (MOBILE-1000753765) [ResponseFilter:]: == URL:/ft/mcsend/v1/fxrate/fetch processed, total time:6932 msec ==
-----------------------------------------

	public McFxRateFetchResponse fetchMCFxRate(final McFxRateFetchRequest request) {
		McFxRateFetchResponse response = new McFxRateFetchResponse();
		return execute(request, response, req -> {
			boolean isNonUSDSettlement = false;
			Double marginPerc = null;
			Double fxRate = null;
			Double conversionRate = null;
			String toCurrency = request.getToCurrency();
			Integer timeToLive = null;
			
			List<McProduct> productByCurrAndType = mcSendRepository.getProductByCurrAndType(request.getToCurrency(),
					request.getTransferType());
			if (!productByCurrAndType.isEmpty()) {
				McProduct mcProduct = productByCurrAndType.get(0);
				if (Objects.nonNull(mcProduct) && StringUtils.isNotBlank(mcProduct.getCurrencyCode())
						&& mcProduct.getCurrencyCode().equalsIgnoreCase(mcProduct.getSendCurrency())) {
					isNonUSDSettlement = true;
				}
			}
			log.info("isNonUSDSettlement flag is :: {}", isNonUSDSettlement);
			if(!isNonUSDSettlement) {
				log.debug("continuing with non USD settlement flow");
				ExchangeRateRequest exchangeRateRequest = new ExchangeRateRequest();
				String dealtCurrency = CURR_AED;
				String buyCurrency = CURR_USD;
				String sellCurrency = CURR_AED;
				exchangeRateRequest.addRate(buyCurrency, sellCurrency, dealtCurrency);
				exchangeRateRequest.setCreditValueDate(new Date());
				exchangeRateRequest.setCustomerRateSegment(MCSEND_SEGMENT);
				exchangeRateRequest.setAmount(request.getAmount());
				
				// 1.Fetch AED to USD rate
				FxRateGetRateResponse exchangeRateResponse = exchangeRateServiceInvoker
						.fetchExchangeRate(exchangeRateRequest);
				if (Objects.nonNull(exchangeRateResponse)
						&& RATE_MODE_REALTIME.equalsIgnoreCase(exchangeRateResponse.getCommon().getRateMode())
						&& exchangeRateResponse.getRatesResponse().isEmpty()) {
					throw new AppException(ErrorCodes.ERROR_FETCH_FX_RATE);
				}

				if (Objects.nonNull(exchangeRateResponse)
						&& !RATE_MODE_REALTIME.equalsIgnoreCase(exchangeRateResponse.getCommon().getRateMode())
						&& exchangeRateResponse.getRateResponse().isEmpty()) {
					throw new AppException(ErrorCodes.ERROR_FETCH_FX_RATE);
				}
				
				RateResponse rateResponse = RATE_MODE_REALTIME.equalsIgnoreCase(exchangeRateResponse.getCommon().getRateMode())
						? exchangeRateResponse.getRatesResponse().get(0)
						: exchangeRateResponse.getRateResponse().get(0);
				Double aedToUsdRate = 1/rateResponse.getSellingRate();
				
				// 2.Fetch USD to FCY rate from DB
				
				McFcyRate mcFcyRate = mcSendRepository.getMcFcyRate(toCurrency, request.getTransferType());
				if (Objects.isNull(mcFcyRate)) {
					throw new AppException(ErrorCodes.ERROR_FETCH_FX_RATE);
				}
				Double usdToFcyRate = mcFcyRate.getFxRate();
				conversionRate = aedToUsdRate * usdToFcyRate;
				log.info("conversionRate received in non USD settlement flow is :: {}", conversionRate);
				
			}else {
				//getDeal invocation
				log.debug("continuing with USD settlement flow :: ");
				FxRateFetchRequest fxRatefetchReq = new FxRateFetchRequest();
				fxRatefetchReq.setFromCurrency(request.getFromCurrency());
				fxRatefetchReq.setToCurrency(toCurrency);
				fxRatefetchReq.setTransferCurrency(request.getTransferCurrency());
				fxRatefetchReq.setAmount(request.getAmount());
				fxRatefetchReq.setTxnRef(request.getTxnRef());
				GetDealResponse dealResponse = getDeal(fxRatefetchReq);
				log.debug("Deal resp received is :: {}", dealResponse);
				if (Objects.nonNull(dealResponse)&&Objects.nonNull(dealResponse.getRate())) {
					conversionRate = 1/dealResponse.getRate().getValue();
					timeToLive = dealResponse.getTimeToLive();
				}else {
					throw new AppException(ErrorCodes.SYS_TECHNICAL_ERROR);
				}
				log.info("conversionRate received in USD settlement flow is :: {} and timeToLive is :: {}", conversionRate, timeToLive);
			}
			
			// 3.fetch margin
			//Double fxRate = aedToFcyRate;
			if (!productByCurrAndType.isEmpty()) {
				McProduct mcProduct = productByCurrAndType.get(0);
				if (Objects.nonNull(mcProduct)) {
					List<String> staffSectorList = settingsRepository.getStaffSectorList();
					if (SessionContext.getSession().getUser().identifyStaff(staffSectorList)) {
						marginPerc = mcProduct.getStaffFxMargin();
					}else
						marginPerc = mcProduct.getFxMargin();
				}
			}
			if (Objects.nonNull(marginPerc)) {
				fxRate = (conversionRate * (1 - marginPerc / 100));
			}
			McFxRate mcFxRate = new McFxRate();
			mcFxRate.setRate(new Amount(fxRate, toCurrency));
			mcFxRate.setTransferAmount(new Amount(fxRate * request.getAmount(), toCurrency));
			mcFxRate.setFromCurrency(request.getFromCurrency());
			mcFxRate.setToCurrency(toCurrency);
			mcFxRate.setTimeToLive(timeToLive);
			List<McFxRate> mcFxRates = new ArrayList<>();
			mcFxRates.add(mcFxRate);
			response.setMcFxRates(mcFxRates);
			log.debug("McFxRate is :: {}", mcFxRate.getRate());
			
			// 4. UPDATE rates in txnsession
			TxnSession txnSession = sessionRepository.findTxnSessionByTxnRef(req.getTxnRef());
			String exchangeRateStr = txnSession.getExchangeRate();
			log.debug("exchangeRateStr received from DB is :: {}", exchangeRateStr);
			FxRateGetDealResponse fxRateDealResponse = null;
			if(isNonUSDSettlement) {
				if (StringUtils.isNotBlank(exchangeRateStr)) {
					fxRateDealResponse = JsonUtils.convertToObject(FxRateGetDealResponse.class, exchangeRateStr);
					log.debug("exchangeRate received from deal service is :: {}", fxRateDealResponse);
				}else {
					log.error("Didnt receive exchangerate infor from session repo");
				}
			}
			McExchangeRate mcExchangeRate = new McExchangeRate();
			//if fx rate not exist in session
			if (StringUtils.isNotBlank(exchangeRateStr)) {
				mcExchangeRate = JsonUtils.convertToObject(McExchangeRate.class, exchangeRateStr);
			}
			mcExchangeRate.setFxRate(conversionRate);//dealWrapperRate
			mcExchangeRate.setFxRateWithMargin(fxRate);
			mcExchangeRate.setFxMargin(marginPerc);
			mcExchangeRate.setTrapiFxRate(conversionRate);//dealWrapperRate
			mcExchangeRate.setExchangeRate(!Objects.isNull(fxRateDealResponse)?getExchangeRateObj(fxRateDealResponse):null);
			log.info("final mcExchangeRate formed is :: {}", mcExchangeRate);
			
			TxnSession session = new TxnSession();
			session.setExchangeRate(JsonUtils.convertToJson(mcExchangeRate));
			session.setTxnRef(req.getTxnRef());
			log.info("Update TXN Session | txnRef: {} exchangerate:{}",req.getTxnRef(),JsonUtils.convertToJson(mcExchangeRate));
			sessionRepository.updateExchangeRate(session);

			return response;
		});
	}

----------------------------------------------------
public FxRateGetRateResponse fetchExchangeRate(ExchangeRateRequest iibRequest) {
		return invoke(ServiceURLs.FX_EXCHANGE_RATE,iibRequest,requestComposer, responseComposer);
	}

----------------------------------------------------
protected <T, R> R invoke(final ServiceURLs serviceURL, T reqObj, Function<T, String> requestComposer, Function<ConnectorResponse, R> responseComposer) {
		ConnectorResponse response = null;
		R respObj = null;
		long t1 = System.currentTimeMillis();
		try {
			serviceInvokerHelper.populateServicUrlEnum(serviceURL);
			String request = requestComposer.apply(reqObj);
			response = httpConnector.post(serviceURL, request, null);
			handleResponse(response, serviceURL);
			respObj = responseComposer.apply(response);
		} catch (Exception e) {
			if (e instanceof AppException || e instanceof SysException) {
				throw e;
			}
			log.error("service invoke failed.." , e);
			throw new AppException(ErrorCodes.SYS_TECHNICAL_ERROR, e);
		} finally {
			log.debug("Service:{} invocation time:{} msec", serviceURL, System.currentTimeMillis() - t1);
			captureHttpStatus(response);
		}
		return respObj;
	}

-------------------------------------------------------
private final Function<ExchangeRateRequest,String> requestComposer = (iibRequest)->{	   
	    Map<String, Object> reqMap = new HashMap<>();
	    SessionInfo sessionInfo = SessionContext.getSession();
	    reqMap.put(APPLICATION_AREA,FABUtils.INSTANCE.getIibReqApplicationArea(sessionInfo.getChannelType(), localeHelper.resolveLanguage(), sessionInfo.getXref()));
	    reqMap.put(RATE_REQ_OBJECT, populateIIBRequest(iibRequest));
	    return JsonUtils.convertToJson(reqMap);
	};
		
	private final Function<ConnectorResponse, FxRateGetRateResponse> responseComposer = (response) -> {
		FxRateGetRateResponse serviceResponse = new FxRateGetRateResponse();
		if (AppConstants.SUCCESS.equalsIgnoreCase(JsonUtils.getJsonPrimitive(response.getJsonResponse(), "$.responseStatus.status"))) {
			serviceResponse = JsonUtils.convertToObject(FxRateGetRateResponse.class, response.getJsonResponse());
		} else {
			throw new AppException(ErrorCodes.ERROR_FETCH_FX_RATE);
		}	
		
		return serviceResponse;
	};




https://www.credly.com/users/umer-farooq.1cd67eef/badges
https://cs.lpi.org/caf/Xamman/certification/verify/LPI000281162/jjngcyhqvv
http://81cd1176253f3f59d435-ac22991740ab4ff17e21daf2ed577041.r77.cf1.rackcdn.com/Certificates/ScrumFundamentalsCertified-UmerFarooq-554089.pdf
http://certification.salesforce.com/certification-detail-print?conId=0034A00002p

*/5 * * * *
If a user enters a credit card number:

It will check if the card is from one of these banks: FIRST GULF BANK, NATIONAL BANK OF ABU DHABI, or FIRST ABU DHABI BANK.
If the card is from one of these banks:
It will make sure the account is in AED (Emirati Dirham) and belongs to the logged-in user.
If the card is not from one of these banks:
It will check if it is a valid IBAN number.

0 0 5 * * ?
 filters records to only include those that have been modified within the past 24 hours from the current time.

Detailed Breakdown for Stakeholders with Justifications
Product Content Configuration:

Integration with Sitecore API:
Task: Develop robust API clients and handle authentication, data retrieval, and error handling.
Justification: Integrating with the Sitecore API is essential to ensure real-time updates and accurate product information on the website. Robust error handling and authentication are necessary to maintain data integrity and security.
Estimation: 2 weeks
Database Design:
Task: Create a database schema to efficiently store and query product details.
Justification: A well-designed database schema ensures that product data is stored efficiently and can be retrieved quickly, which is crucial for performance and scalability.
Estimation: 1 week
API Development:
Task: Build scalable REST APIs to serve the product content to the frontend applications.
Justification: Exposing product details through a REST API allows for decoupling the backend and frontend, making the system more modular and easier to maintain. It also facilitates integration with other systems or future enhancements.
Estimation: 2 weeks
UI/UX - Capture User Data:

Content Configuration:
Task: Set up configurations for content delivery, ensuring it is responsive to user inputs and preferences.
Justification: Dynamic content delivery enhances user experience by providing personalized information based on user inputs, which can increase user engagement and satisfaction.
Estimation: 1 week
Data Capture Endpoints:
Task: Develop backend endpoints to securely capture and store user data.
Justification: Capturing user data accurately and securely is crucial for compliance with data protection regulations and for personalizing user experience. Ensuring secure data handling prevents potential data breaches.
Estimation: 2 weeks
Validation and Processing:
Task: Implement server-side validation to ensure data integrity and security.
Justification: Validating data on the server-side helps prevent invalid or malicious data from entering the system, thus protecting the application from potential attacks and ensuring data quality.
Estimation: 1 week
Quote Functionality:

Service Integration:
Task: Develop service layer to communicate with insurance microservices.
Justification: Integrating with external microservices allows for leveraging existing functionalities and data from insurance providers, which can reduce development time and improve reliability.
Estimation: 3 weeks
Quote Logic Enhancement:
Task: Update existing quote creation logic to handle new insurance options.
Justification: Enhancing the quote functionality to include additional insurance options provides users with more choices, potentially increasing conversion rates and customer satisfaction.
Estimation: 2 weeks
Testing and Validation:
Task: Perform extensive testing to ensure the new quote functionality works seamlessly with existing systems.
Justification: Thorough testing is essential to identify and fix bugs, ensuring that the new features work correctly and do not introduce any regressions. This helps maintain system stability and reliability.
Estimation: 2 weeks

Summary with Justifications
Total Duration: Approximately 13 weeks
Resources: Depending on the team size and expertise, parallel task execution might reduce the overall time.
Justifications:
Integration Tasks: Necessary for ensuring that the backend can communicate effectively with external systems and provide real-time, accurate data to the frontend.
Database Design: Critical for performance, scalability, and efficient data retrieval.
API Development: Facilitates modularity, maintainability, and potential future integrations.
Content Configuration: Enhances user experience through personalized content delivery.
Data Capture and Validation: Ensures data integrity, compliance with regulations, and security against potential threats.
Service Integration and Logic Enhancement: Provides users with enhanced functionalities and options, improving overall service offering.
Testing and Validation: Ensures the reliability and stability of the system, preventing future issues.
This detailed and justified plan helps stakeholders understand the necessity of each task, the effort involved, and the benefits these tasks bring to the overall project. This understanding is crucial for accurate resource allocation and time estimation.


----------------------------
Product Content Configuration
Tasks:
Integration with Sitecore API:
Needs to be built from scratch: Developing API clients to fetch product data from Sitecore.
Database Design:
Needs to be built from scratch: Creating a database schema to store product details.
API Development:
Needs to be built from scratch: Building REST APIs to expose product details.
UI/UX - Capture User Data
Tasks:
Content Configuration:
Needs to be built from scratch: Setting up configurations for content delivery based on user data.
Data Capture Endpoints:
Needs to be built from scratch: Developing endpoints to capture and store user data.
Validation and Processing:
Needs to be built from scratch: Implementing server-side validation and processing for captured data.
Quote Functionality
Tasks:
Service Integration:
Needs to be built from scratch: Developing service layers to communicate with insurance microservices.
Quote Logic Enhancement:
Enhancement: Updating existing quote creation logic to handle new insurance options.
Testing and Validation:
Needs to be built from scratch: Performing extensive testing of the new and enhanced functionalities.
Summary of Tasks
Needs to be built from scratch:
Product Content Configuration

Integrate with Sitecore API
Design and implement database schema for product data
Develop REST APIs to expose product details
UI/UX - Capture User Data

Configure content delivery based on user data
Develop endpoints for capturing and storing user data
Implement server-side validation and processing
Quote Functionality

Integrate with insurance microservices
Perform comprehensive testing of new and enhanced functionalities
Needs to be enhanced:
Quote Functionality
Update the existing quote creation logic to handle new insurance options
Detailed Justification
Product Content Configuration:

Integration with Sitecore API: This task involves building the integration from scratch as it requires developing new API clients and handling specific authentication and data retrieval mechanisms.
Database Design: Creating a new database schema is necessary to store the product data effectively.
API Development: New REST APIs are required to expose product details, ensuring that frontend applications can access this data seamlessly.
UI/UX - Capture User Data:

Content Configuration: This involves setting up a new configuration system to deliver content dynamically based on user inputs, which is a new build.
Data Capture Endpoints: Developing new endpoints to capture and store user data is essential for personalizing the user experience.
Validation and Processing: Implementing server-side validation and processing ensures data integrity and security, which needs to be built from scratch.
Quote Functionality:

Service Integration: This involves building new service layers to communicate with insurance microservices, which is a new task.
Quote Logic Enhancement: Modifying the existing quote creation logic to include new insurance options is an enhancement of the current functionality.
Testing and Validation: Comprehensive testing of both new and enhanced functionalities is crucial to ensure system stability and reliability.
This breakdown helps stakeholders understand the scope of new developments and enhancements, allowing for better estimation of build efforts and resource allocation.
